# EdgeLLM

[![SwiftPM](https://img.shields.io/badge/SwiftPM-Add%20Package-green)](https://swift.org/package-manager/)
[![License](https://img.shields.io/badge/License-Apache--2.0-blue)](LICENSE)
[![Release](https://img.shields.io/github/v/tag/john-rocky/EdgeLLM)](https://github.com/john-rocky/EdgeLLM/releases)

**EdgeLLM** is a Swift Package that currently ships with **three preâ€‘compiled models**  
(~300Â MB XCFramework) so you can run LLMs offline on iOSâ€¯/â€¯macOS *without any extra download*.

> A lightweight 10Â MB runtime + onâ€‘demand weights is on our roadmap.  
> For now we prioritise *â€œit just worksâ€* over minimal binary size.

---

## ğŸš€ Oneâ€‘Line Installation

```swift
// Package.swift
.package(url: "https://github.com/john-rocky/EdgeLLM", from: "0.1.1")
```

*First `swift build` fetches theÂ 300Â MB package; subsequent builds are cached.*

---

## âš¡Â 5â€‘Line QuickÂ Start

```swift
import EdgeLLM
let llm   = try EdgeLLM(modelId: "qwen-0.6b_q0")
let reply = try await llm.chat("Hello!")
print(reply)
```

Because the models are bundled, **no runtime download** is needed.  
Works entirely offlineâ€”even in AirplaneÂ Mode.

---

## ğŸ“š BundledÂ Models

| ID | Params | Languages | SuggestedÂ RAM | TypicalÂ Use |
|----|--------|-----------|--------------|-------------|
| `qwen-0.6b_q0`    | 0.6â€¯B | EN Â· JA Â· ZH | â‰¥â€¯4â€¯GB | lightweight chat, summaries |
| `gemma-2b_q4`     | 2â€¯B   | EN          | â‰¥â€¯4â€¯GB | Q&A, code completion |
| `phi-3.5-mini_q4` | 3.5â€¯B | Multi       | â‰¥â€¯6â€¯GB | multilingual chat, translation |

*More models comingâ€”see roadmap.*

---

## âœ¨Â Features

* **Offline by default** â€“ all weights in the app bundle  
* **Metalâ€‘accelerated** â€“Â â‰ˆâ€¯15â€¯tok/s on iPhoneÂ 15Â Pro (Phiâ€‘3.5Â Miniâ€¯int4)  
* **BYOM** â€“ sideâ€‘load any `.tar.zst` via `EdgeLLM.registerLocalModel()`  
* **Apacheâ€‘2.0** â€“ businessâ€‘friendly licence  

---

## ğŸ—ºÂ Roadmap

| Milestone | ETA |
|-----------|-----|
| 10Â MB runtime + onâ€‘demand weights | Q3Â 2025 |
| Android / Vulkan build | Q3Â 2025 |
| Highâ€‘perfÂ 7â€¯B kernels (plugin) | Planned |
| WebAssembly demo | Research |

---

## ğŸ’¬ Community

* **Discord** â€“ <https://discord.gg/edgellm>  
* **GitHub Discussions** â€“ open a topic under *Q&A*.

---

## ğŸ”’Â License

Apacheâ€‘2.0 â€” see `LICENSE`.  
Portions derived from MLCâ€‘LLM (Apacheâ€‘2.0); see `LICENSE-THIRD-PARTY.txt`.

---

*Generated 2025-07-03*
