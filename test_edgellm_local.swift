#!/usr/bin/env swift

import Foundation

// EdgeLLMã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ãŸã‚ã®ç°¡å˜ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆ
// ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã®å‹•ä½œç¢ºèªç”¨

print("EdgeLLM Local Test Starting...")

// ãƒ†ã‚¹ãƒˆç”¨ã®é–¢æ•°ã‚’å®šç¾©
func testEdgeLLM() async {
    do {
        print("Loading EdgeLLM with Qwen 0.6B model...")
        
        // ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’ä½¿ã£ã¦ç›´æ¥ãƒ†ã‚¹ãƒˆ
        let modelPath = "/Users/agmajima/.cache/mlc_llm/model_weights/hf/mlc-ai/Qwen3-0.6B-q0f16-MLC"
        
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ã‚’ç¢ºèª
        let fileManager = FileManager.default
        if fileManager.fileExists(atPath: modelPath) {
            print("âœ… Model found at: \(modelPath)")
            
            // EdgeLLMã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ãƒ†ã‚¹ãƒˆï¼ˆå®Ÿéš›ã«ã¯Swiftã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã«EdgeLLMãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒå¿…è¦ï¼‰
            print("ğŸ“ Test prompt: 'Hello, how are you?'")
            
            // NOTE: ã“ã®éƒ¨åˆ†ã¯å®Ÿéš›ã®EdgeLLMãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒãƒªãƒ³ã‚¯ã•ã‚ŒãŸæ™‚ã«å‹•ä½œã™ã‚‹
            // let response = try await EdgeLLM.chatWithLocalModel("Hello, how are you?", model: .qwen05b)
            // print("ğŸ¤– Response: \(response)")
            
            print("âš ï¸  EdgeLLMãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ãƒªãƒ³ã‚¯ã™ã‚‹ã“ã¨ã§å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆãŒå¯èƒ½ã«ãªã‚Šã¾ã™")
            
        } else {
            print("âŒ Model not found at: \(modelPath)")
        }
        
    } catch {
        print("âŒ Error: \(error)")
    }
}

// éåŒæœŸé–¢æ•°ã‚’å®Ÿè¡Œ
Task {
    await testEdgeLLM()
    print("Test completed.")
    exit(0)
}

// ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ãƒ–ãƒ­ãƒƒã‚¯
RunLoop.main.run()