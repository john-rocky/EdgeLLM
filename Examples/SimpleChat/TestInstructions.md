# SimpleChat Test Instructions

## Quick Test Guide

### 1. Open in Xcode

```bash
cd /Users/majimadaisuke/Downloads/mlc-llm/EdgeLLM/Examples/SimpleChat
open SimpleChat.xcodeproj
```

### 2. Build and Run

1. Select your iPhone simulator (iPhone 15 Pro recommended)
2. Press Cmd+R to build and run
3. The app should launch with the EdgeLLM chat interface

### 3. Current Status

The app currently uses a mock implementation that simulates EdgeLLM responses. This allows you to:
- Test the UI and interaction flow
- See how model selection works
- Experience the chat interface

### 4. Mock Behavior

When you send a message, the mock will:
- Show a loading indicator
- Simulate a 1-second delay
- Return a response like: "This is a mock response from [Model Name]. In a real app, this would be generated by the LLM."

### 5. Testing with Real EdgeLLM

To test with the real EdgeLLM package (once models are available):

1. Remove MockEdgeLLM.swift from the project
2. Uncomment `import EdgeLLM` in ContentView.swift
3. Update Package.swift to use the EdgeLLM package
4. Build and run

### 6. Features to Test

- [x] Send messages
- [x] Switch between models (Qwen 0.5B, Gemma 2B, Phi-3.5 Mini)
- [x] View conversation history
- [x] Auto-scroll to latest message
- [x] Loading states
- [x] Error handling

### 7. Known Limitations

- Currently using mock implementation
- Real models need to be downloaded first (1-3GB)
- First message may take longer due to model loading

## Troubleshooting

### Package Resolution Failed

If you see "Missing package product 'EdgeLLM'":
1. The app is currently set to use the local EdgeLLM package
2. Make sure you're on the `complete-package` branch
3. Or use the mock implementation (already included)

### Build Errors

If you encounter build errors:
1. Clean build folder (Cmd+Shift+K)
2. Reset package caches (File → Packages → Reset Package Caches)
3. Ensure you're using Xcode 15.0 or later

## Next Steps

Once models are hosted:
1. Update EdgeLLM package to include model URLs
2. Test model downloading
3. Verify actual LLM responses
4. Measure performance on real device